{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca01381-cd62-42c6-b7ea-54fa9d50d13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Author : Santosh Kumar Udayakumar\n",
    "#Function : Build the subgraph between Nybroplan and Ropsten and calculate the elapased time between the stops .\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import timedelta\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"routes_master_data.csv.gz\")\n",
    "\n",
    "# Filter water routes\n",
    "water_routes = data[data['TransportMode'] == 'water']\n",
    "water_routes = water_routes[water_routes['Private_Code'].isin([80, 82, 83, 84, 89])]\n",
    "\n",
    "# Filter stops\n",
    "stops = data[data['Private_Code'].isin([13, 76, 57, 67, 53, 515, 176])]\n",
    "\n",
    "route = data[data['Route_Name'] == 'Dalarö']\n",
    "\n",
    "# Get unique Route_Name\n",
    "unique_route_names = water_routes['Route_Name'].unique()\n",
    "\n",
    "# Filter by specific Route_Name\n",
    "Norra = water_routes[water_routes['Route_Name'] == 'Norra Lagnö']\n",
    "\n",
    "# Get column names\n",
    "water_routes_columns = water_routes.columns.tolist()\n",
    "\n",
    "# Select specific columns\n",
    "routes_df = data[['Route_Name', 'Direction', 'Private_Code', 'StopPlace.Name', 'Order',\n",
    "           'StopPlace.Latitude', 'StopPlace.Longitude', 'TransportMode', 'ArrivalTime', 'DepartureTime']]\n",
    "\n",
    "# Get the first 100 rows\n",
    "stop_points = routes_df.head(100)\n",
    "stop_points.to_csv('stops.csv', index=False)\n",
    "\n",
    "# Get distinct rows\n",
    "updates_routes = routes_df.drop_duplicates(subset=['Route_Name', 'Direction', 'Private_Code', 'StopPlace.Name',\n",
    "                                  'Order', 'TransportMode'], keep='first')\n",
    "updates_routes.to_csv('water_routes.csv', index=False)\n",
    "\n",
    "# Generate routes JSON\n",
    "routes_json = (\n",
    "    updates_routes.drop_duplicates(subset=['Route_Name', 'Direction', 'Order', 'StopPlace.Latitude',\n",
    "                                 'StopPlace.Longitude', 'StopPlace.Name', 'TransportMode'])\n",
    "    .groupby(['Route_Name', 'Direction'])\n",
    "    .apply(lambda group: {\n",
    "        \"Route_Name\": group['Route_Name'].iloc[0],\n",
    "        \"Direction\": group['Direction'].iloc[0],\n",
    "        \"Stops\": group[['Order', 'StopPlace.Name', 'TransportMode', 'StopPlace.Latitude', 'StopPlace.Longitude']]\n",
    "        .rename(columns={\n",
    "            'StopPlace.Name': 'StopName',\n",
    "            'StopPlace.Latitude': 'Latitude',\n",
    "            'StopPlace.Longitude': 'Longitude'\n",
    "        }).to_dict(orient='records')\n",
    "    })\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "with open('other_routes.json', 'w') as f:\n",
    "    json.dump(routes_json, f, indent=4)\n",
    "\n",
    "# Reassign unique sequential order numbers and generate JSON\n",
    "routes_json = (\n",
    "    updates_routes.drop_duplicates(subset=['Route_Name', 'Direction', 'StopPlace.Name', 'StopPlace.Latitude', 'StopPlace.Longitude'])\n",
    "    .sort_values(by=['Route_Name', 'Direction', 'Order'])\n",
    "    .assign(Order=lambda x: x.groupby(['Route_Name', 'Direction']).cumcount() + 1)\n",
    "    .groupby(['Route_Name', 'Direction'])\n",
    "    .apply(lambda group: {\n",
    "        \"Route_Name\": group['Route_Name'].iloc[0],\n",
    "        \"Direction\": group['Direction'].iloc[0],\n",
    "        \"Stops\": group[['Order', 'StopPlace.Name', 'TransportMode', 'StopPlace.Latitude', 'StopPlace.Longitude']]\n",
    "        .rename(columns={\n",
    "            'StopPlace.Name': 'StopName',\n",
    "            'StopPlace.Latitude': 'Latitude',\n",
    "            'StopPlace.Longitude': 'Longitude'\n",
    "        }).to_dict(orient='records')\n",
    "    })\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "with open('water_routes.json', 'w') as f:\n",
    "    json.dump(routes_json, f, indent=4)\n",
    "\n",
    "# Load JSON files\n",
    "#a = json.load(open('other_routes.json'))\n",
    "#b = json.load(open('water_routes.json'))\n",
    "\n",
    "# Calculate time difference\n",
    "stops_data = routes_df.copy()\n",
    "stops_data['TimeDifference'] = (pd.to_datetime(stops_data['DepartureTime']) - \n",
    "                                pd.to_datetime(stops_data['ArrivalTime'])).dt.total_seconds() / 60\n",
    "\n",
    "# Prepare the output data\n",
    "output_data = stops_data.assign(\n",
    "    NeighborStop=stops_data['StopPlace.Name'].shift(-1)\n",
    ").rename(columns={\n",
    "    'StopPlace.Name': 'StopName',\n",
    "    'Route_Name': 'RouteName',\n",
    "    'Private_Code': 'LineNumber',\n",
    "    'TransportMode': 'TravelMode',\n",
    "    'StopPlace.Latitude': 'StopLatitude',\n",
    "    'StopPlace.Longitude': 'StopLongitude'\n",
    "})[['StopName', 'RouteName', 'LineNumber', 'TravelMode', 'StopLatitude', 'StopLongitude', 'NeighborStop', 'TimeDifference']]\n",
    "\n",
    "# Convert to JSON\n",
    "output_json = output_data.to_json(orient='records', indent=4)\n",
    "\n",
    "# Save JSON to file\n",
    "with open('output.json', 'w') as f:\n",
    "    f.write(output_json)\n",
    "\n",
    "# Print JSON output\n",
    "print(output_json)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
